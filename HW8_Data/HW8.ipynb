{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "179a59b4-7f2e-4a00-b625-e78dcbe85bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# # Creating Train / Val / Test folders (One time use)\n",
    "root_dir = 'HW8_Data'\n",
    "cats = '/cats'\n",
    "dogs = '/dogs'\n",
    "\n",
    "os.makedirs(root_dir +'/train' + cats)\n",
    "os.makedirs(root_dir +'/train' + dogs)\n",
    "os.makedirs(root_dir +'/val' + cats)\n",
    "os.makedirs(root_dir +'/val' + dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7812e4f7-a375-4abd-81b0-e7fbb292bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_filenames = []\n",
    "for i in np.arange(12500):\n",
    "    filename = 'HW8_Data/cat.%d.jpg' % i\n",
    "    cat_filenames.append(filename)\n",
    "\n",
    "cat_train = cat_filenames[:10000]\n",
    "cat_val = cat_filenames[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f3dff83-413f-4d08-8827-38731e6f6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_filenames = []\n",
    "for i in np.arange(12500):\n",
    "    filename = 'HW8_Data/dog.%d.jpg' % i\n",
    "    dog_filenames.append(filename)\n",
    "\n",
    "dog_train = dog_filenames[:10000]\n",
    "dog_val = dog_filenames[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e59d23b9-a6f0-4ea5-9ccd-32349e0b1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy-pasting images\n",
    "for name in cat_train:\n",
    "    shutil.copy(name, \"HW8_Data/train/cats\")\n",
    "\n",
    "for name in cat_val:\n",
    "    shutil.copy(name, \"HW8_Data/validation/cats\")\n",
    "\n",
    "for name in dog_train:\n",
    "    shutil.copy(name, \"HW8_Data/train/dogs\")\n",
    "    \n",
    "for name in dog_val:\n",
    "    shutil.copy(name, \"HW8_Data/validation/dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9682d906-c74b-45a2-88a4-9207c458d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as ts\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e9f1b48-1b84-4e9b-9ee4-67468043a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = SGD(lr=0.002, momentum=0.8)\n",
    "loss = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9a38b72d-2844-4f52-b0de-de3875d83cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################    \n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "\n",
    "base = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150,150,3))(inputs)\n",
    "\n",
    "vectors = keras.layers.MaxPooling2D(pool_size=(2,2))(base)\n",
    "\n",
    "vectors = keras.layers.Flatten()(vectors)\n",
    "\n",
    "inner = keras.layers.Dense(64, activation='relu')(vectors)\n",
    "\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(inner)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "##################################################    \n",
    "optimizer = SGD(lr=0.002, momentum=0.8)\n",
    "loss = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=['accuracy', 'std']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "04c74d47-56d6-4d7c-bb4b-5477bd5aa14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 175232)            0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                11214912  \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "80e5e860-58ca-4cf1-b327-6ec1d276db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8c3f71d-faac-4132-8ccd-5680f00411aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e19a7883-7da4-414e-a8e0-561b0eeb81ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_generator.flow_from_directory('./HW8_Data/train/', \n",
    "                              target_size=(150,150), \n",
    "                              batch_size=20, class_mode='binary')\n",
    "\n",
    "val_ds = validation_generator.flow_from_directory('./HW8_Data/validation/', \n",
    "                              target_size=(150,150), \n",
    "                              batch_size=20,\n",
    "                                    shuffle=False, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8c28caa6-1d38-46b9-9339-f9657e61b53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'binary'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bcc82168-2469-4c8e-8ab3-5e78cf0db9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 21s 205ms/step - loss: 0.7244 - accuracy: 0.4816 - val_loss: 0.6781 - val_accuracy: 0.9960\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 0.6928 - accuracy: 0.5084 - val_loss: 0.6740 - val_accuracy: 0.6480\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 22s 219ms/step - loss: 0.6904 - accuracy: 0.5366 - val_loss: 0.6597 - val_accuracy: 0.5670\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 21s 205ms/step - loss: 0.6894 - accuracy: 0.5548 - val_loss: 0.6933 - val_accuracy: 0.1950\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 0.6867 - accuracy: 0.5457 - val_loss: 0.6643 - val_accuracy: 0.3890\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 22s 224ms/step - loss: 0.6859 - accuracy: 0.5439 - val_loss: 0.6510 - val_accuracy: 0.4620\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 0.6871 - accuracy: 0.5357 - val_loss: 0.5799 - val_accuracy: 0.6560\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 22s 219ms/step - loss: 0.6755 - accuracy: 0.5711 - val_loss: 0.6139 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 0.6902 - accuracy: 0.5467 - val_loss: 0.6220 - val_accuracy: 0.4830\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 0.6837 - accuracy: 0.5537 - val_loss: 0.5697 - val_accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f0cad4f9-3229-4eb7-8d6e-1db0beabf0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007482303263297786"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "be5779f7-80e5-4066-a34b-13bbed34e75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_ds = train_generator.flow_from_directory('./HW8_Data/train/', \n",
    "                              target_size=(150,150), \n",
    "                              batch_size=20, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ef3fa376-4fd9-4a44-b92c-8e3830f4e8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.6880 - accuracy: 0.5450 - val_loss: 0.7225 - val_accuracy: 0.2010\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.6841 - accuracy: 0.5520 - val_loss: 0.5627 - val_accuracy: 0.8690\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.6856 - accuracy: 0.5525 - val_loss: 0.6424 - val_accuracy: 0.5220\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.6835 - accuracy: 0.5600 - val_loss: 0.6279 - val_accuracy: 0.6230\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.6838 - accuracy: 0.5490 - val_loss: 0.6471 - val_accuracy: 0.5150\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.6722 - accuracy: 0.5885 - val_loss: 0.6055 - val_accuracy: 0.5590\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 0.6794 - accuracy: 0.5695 - val_loss: 0.6629 - val_accuracy: 0.4550\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 0.6825 - accuracy: 0.5680 - val_loss: 0.6438 - val_accuracy: 0.5920\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 0.6811 - accuracy: 0.5635 - val_loss: 0.6193 - val_accuracy: 0.6070\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.6833 - accuracy: 0.5620 - val_loss: 0.7492 - val_accuracy: 0.2140\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "47d29301-0070-425c-a7a2-ea07adb15dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6483260333538056"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a23718d3-8806-414f-803c-e784fc9ee0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4854000061750412"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_accuracy'][5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea0ccd0-238e-4d7b-bc9b-d7e47569921e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
